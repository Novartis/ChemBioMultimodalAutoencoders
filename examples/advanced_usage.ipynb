{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Usage Tutorial\n",
    "This notebooks aims at showing a few advabced features of the translation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing the needed parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need to import a few things first\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# changing working directory\n",
    "# for imports to work\n",
    "from pathlib import Path\n",
    "path = Path(os.getcwd())\n",
    "print(path)\n",
    "os.chdir(path.parent)\n",
    "\n",
    "# import the encoders and decoders we want to use\n",
    "from multimodal_autoencoders.model.encoders import DynamicEncoder\n",
    "from multimodal_autoencoders.model.decoders import DynamicDecoder\n",
    "\n",
    "# import the Autoencoder class\n",
    "from multimodal_autoencoders.base.autoencoder import VariationalAutoencoder\n",
    "\n",
    "# import a discriminator and a classifier\n",
    "from multimodal_autoencoders.model.classifiers import Discriminator, SimpleClassifier\n",
    "\n",
    "# import the JointTrainer aka the brains of the operation\n",
    "from multimodal_autoencoders.joint_trainer import JointTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up the data\n",
    "We will use the same synthetic data set up as in the basic usage example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the random generator\n",
    "rng = np.random.default_rng(seed = 1234)\n",
    "\n",
    "# create some latent information common to all modalities\n",
    "train_latent_information = rng.random(size = (100, 25))\n",
    "\n",
    "# small helper function for our synthetic data\n",
    "def generate_modality(latent_information: np.array, n_random_dims: int, samples: int = 100):\n",
    "    ar = np.concatenate((latent_information, rng.random(size = (100, n_random_dims))), axis=1)\n",
    "    rng.shuffle(ar, axis=1)\n",
    "\n",
    "    return ar\n",
    "\n",
    "# define the data dictionary\n",
    "# this will be the first part you'll need to hold your actual data\n",
    "train_data_dict = {\n",
    "    \"modality_1\": generate_modality(train_latent_information, 25),\n",
    "    \"modality_2\": generate_modality(train_latent_information, 50),\n",
    "    \"modality_3\": generate_modality(train_latent_information, 75)}\n",
    "\n",
    "\n",
    "# we will also create a separate validation data set sharing some similarity to the training data\n",
    "val_latent_information = train_latent_information * 0.8 + rng.random(size = (100, 25)) * 0.2\n",
    "val_data_dict = {\n",
    "    \"modality_1\": generate_modality(val_latent_information, 25),\n",
    "    \"modality_2\": generate_modality(val_latent_information, 50),\n",
    "    \"modality_3\": generate_modality(val_latent_information, 75)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting up the models\n",
    "### 3.1 Autoencoders with individual pretraining and frozen joint training\n",
    "Depending on your use case, a pretraining of one or multuple models might be helpful for the overall performance. Additionally, you might want to keep this pre-trained model in its trained state for the joint training and only let the other models adapt to it. For such a scenario, each autoencoder accepts two more argumens:\n",
    "- pretrain_epochs: integer numver of epochs the model should be pretrained\n",
    "- train_joint: boolean flag whether the model should also be trained in joint mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"modality_1\": VariationalAutoencoder(DynamicEncoder(50, 42, 2), DynamicDecoder(50, 42, 36, 2), \"adam\", 0.001),\n",
    "    \"modality_2\": VariationalAutoencoder(DynamicEncoder(75, 50, 2), DynamicDecoder(75, 50, 36, 2), \"adam\", 0.001),\n",
    "    \"modality_3\": VariationalAutoencoder(DynamicEncoder(100, 75, 2), DynamicDecoder(100, 75, 36, 2), \"adam\", 0.001, pretrain_epochs = 10, train_joint = False)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(\"adam\", 0.001, 36, len(model_dict), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Classifier and cluster labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.concatenate((np.repeat(0, 50), np.repeat(1, 50))).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SimpleClassifier(\"adam\", 0.001, 36, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Seting up the JointTraner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JointTrainer(\n",
    "        model_dict = model_dict,\n",
    "        discriminator = discriminator,\n",
    "        \n",
    "        classifier = classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train with early stopping\n",
    "Now that all parts of the model are set up again, we can begin training. This time around we don't only want to train the model, but we mant to make sure it stops training as soon as it stops to generalize to unseen data. The method of early stopping allows to do this automatically. The train call provides two further parameters to customize the early stopping procedure:\n",
    "- patience: integer number of epochs that the model is allowed to not improve on unseen data \n",
    "- min_value: float value of minimal difference between validation loss of the previous and the current epoch needed to count as an improvement\n",
    "\n",
    "These parameters should be chosen carefully. Too little patience will lead to the training stopping to early, even though the model would have recovered a few epochs later. Too much patience and the model might train longer than needed. The architecture will store a model checkpoint for you at the beginning of a consecutive series of overfitting epochs. This allows to return the optimal point at which the model was best performing and best generalizing.<br>\n",
    "The min_value needed to count an epoch result as overfitted can be very domain specific. Depending on the scale of your data a larger difference between training and validation loss might be loss of an issue. Always keep in mind to not too small of a value as otherwise you might stop the training prematurely. A good practice is to do a first short training run and evalutate a good min_value based on the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_dict = model.train(\n",
    "    train_data_dict = train_data_dict,\n",
    "    val_data_dict = val_data_dict,\n",
    "    batch_size = 10,\n",
    "    max_epochs = 10,\n",
    "    recon_weight = 3,\n",
    "    beta = 0.001,\n",
    "    disc_weight = 3,\n",
    "    anchor_weight = 1,\n",
    "    cl_weight = 3,\n",
    "    cluster_labels = cluster_data,\n",
    "    use_gpu = False,\n",
    "    patience = 2,\n",
    "    min_value = 10)\n",
    "\n",
    "print(meter_dict[\"loss\"].avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pre-training with a classifier\n",
    "In some cases it might be beneficial to not only pre-train an autoencoder, but to have it influenced by a cluster classifier. This allows to create the original use case published by Dai Yang et al. of pre-training an autoencoder and a classifer, to which the other models get aligned in the joint training phase. The train method of the JointTrainer class provides a \"cluster_modality\" parameter towards this aim. Simply provide the model key to which the classifier should be added during pre-training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"modality_1\": VariationalAutoencoder(DynamicEncoder(50, 42, 2), DynamicDecoder(50, 42, 36, 2), \"adam\", 0.001),\n",
    "    \"modality_2\": VariationalAutoencoder(DynamicEncoder(75, 50, 2), DynamicDecoder(75, 50, 36, 2), \"adam\", 0.001),\n",
    "    \"modality_3\": VariationalAutoencoder(DynamicEncoder(100, 75, 2), DynamicDecoder(100, 75, 36, 2), \"adam\", 0.001, pretrain_epochs = 10, train_joint = False)}\n",
    "\n",
    "# re-intialize the trainer\n",
    "model = JointTrainer(\n",
    "        model_dict = model_dict,\n",
    "        discriminator = discriminator,\n",
    "        classifier = classifier)\n",
    "\n",
    "# launch training with classifier in pre-training\n",
    "# by providing an existing model key through the\n",
    "# cluster_modality parameter\n",
    "meter_dict = model.train(\n",
    "    train_data_dict = train_data_dict,\n",
    "    val_data_dict = val_data_dict,\n",
    "    batch_size = 10,\n",
    "    max_epochs = 10,\n",
    "    recon_weight = 3,\n",
    "    beta = 0.001,\n",
    "    disc_weight = 3,\n",
    "    anchor_weight = 1,\n",
    "    cl_weight = 3,\n",
    "    cluster_labels = cluster_data,\n",
    "    cluster_modality = \"modality_3\",\n",
    "    use_gpu = False)\n",
    "\n",
    "print(meter_dict[\"loss\"].avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7756088dfae82ffe8963c3b0101f571fbcee16e9508b2375e6762c7d087f0f1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
